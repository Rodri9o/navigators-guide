#### Breaking down your infrastructure

In the last section we used Terraform and Ansible to provision your Droplets and deploy your WordPress application. Let's take a look at the process and break it down a bit further. We're going to first look at Terraform and the resources it created using the **main.tf** file. Going through the file you'll see that all resources are individually listed along with arguments being input within each resource block. We deployed a simple blog, and as you can imagine, the more resources you create the longer the file will get. This is going to make it a bit more difficult to manage as time goes on and you begin to create more resources to run additional services. One way to cut that down a bit is by using Terraform modules. Modules allow you to create blocks of reusable infrastructure which can take inputs and provide outputs just like you would with a function in any high level programming language. This also means you can set default values for any parameters a module may accept allowing you to minimize the amount of lines required to spin up your resources as a whole.

If you took a look at the **main.tf** file in the **init_deploy** example code, you'll notice that the last section is actually already using a Terraform module.

```
module "sippin_db" {
  source           = "github.com/cmndrsp0ck/galera-tf-mod.git?ref=v1.0.2"
  ...
}
```

If you compare that block of text to the resource block for `wp_node` towards the top of thee file you'll see that it's quite a bit shorter and cleaner looking. It could actually be shorter depending on how many defaults you prefer to set as well. Additionally, this module isn't just spinning up a single Droplet, it's creating Droplet tags, the Galera cluster nodes, the load balancers, and a floating IP. It also means you can add more resources to an individual module if you'd like or you can always create some outputs and use them with another module.

Another aspect worth mentioning is how you call a module. The most common methods I see used are a local file path, or a remote git repo. A local file path is fine for testing but in most cases you'll want to make use of a remote git repo to take environment isolation one step further than just using file system directories. An example of this would be when running multiple environments. Let's say you're running both a staging and a production environment and you're using a Terraform module stored on your local file system. If both environments point to the same directory for the module and a change is made in staging, the next time you run apply in production, whether you intended to or not, the changes to the module will be carried out. So you may have created or deleted resources without really verifying they work properly. We get around this by using a remote git repo and specifying the version number of the module. Another benefit to this method is simply being able roll back if something does happen to break. So just keep that in mind when you're building things.

**Environments**

  * dev
  * staging
  * prod

Before we jump into deploying Droplets and services all willy-nilly, let's touch on environments and how you can keep the separate. In serious projects you're going to have a dev, staging, and production environment to allow yourself room to tinker, test, and deploy without having to worry about bringing your live site down. Doing a little planning ahead of time will go a long way in preventing headaches. Your Dev environment can vary but usually you're going to be running something locally using Vagrant so you can run some VM's and/or Docker containers. Nothing too crazy about that, just be sure not to store any passwords you actually use in other environments.

When you get to environments you're actually deploying in a shared or public space using Terraform, you want to isolate them from one another. Terraform provides a workspace feature that keeps the terraform.tfstate files separate from one another. However, we're going to stick with using directories for isolation. This can be done a few different ways and often times it comes down to personal preference or whatever works best for your project. Here's an example structure.

```
.
├── ansible.cfg
├── bin/
├── environments/
│   ├── config/
│   │   └── cloud-config.yaml
│   │
│   ├── dev/
│   ├── prod/
│   │   ├── config -> ../config
│   │   ├── group_vars
│   │   ├── host_vars
│   │   ├── main.tf
│   │   ├── terraform.tfvars
│   │   ├── terraform-inventory -> ../terraform-inventory
│   │   └── variables.tf
│   │
│   ├── staging/
│   │   ├── config -> ../config
│   │   ├── group_vars
│   │   ├── host_vars
│   │   ├── main.tf
│   │   ├── terraform.tfvars
│   │   ├── terraform-inventory -> ../terraform-inventory
│   │   └── variables.tf
│   │
│   └── terraform-inventory
│
├── site.yml
├── wordpress.yml
│
└── roles/
```

One other thing to note is that we're not configuring Terraform to use remote state since we're only executing this from a single node and it's really for exercise purposes. Just know that when you're working with a team, you'll want to look into setting up a remote state backend like Consul which supports state locking. If you don't use a remote state backend, you and another team member could execute changes to your infrastructure at the same time leading causing something to break and possibly leading to corruption in your state file. Once that happens you may need to roll back if possible, otherwise you'll have to manually debug the issue and the entries in your state file until you've brought everything back online.

Okay, let's go over a few things to explain the logic behind this type of layout. The first is that we're keeping files that pertain to similar components in separate environments apart from one another. The important thing is that we don't want to run some Ansible or Terraform scripts on the wrong environment and bring everything crashing down. We do this by placing directories in the **environments** dir and each one gets its own subdirectory. Since we're using Terraform, we can place our individual scripts per environment in each directory, and we can go even further by placing different parts of your infrastructure in further subdirectories in order to isolate each of them from one another. There are actually some really great write-ups about this topic online, one of which has actually turned into the book, *"Terraform: Up & Running"* by Yevgeniy Brikman. You can check out his blog post which covers this in more detail: https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca

As mentioned before, it's a good idea to make use of versioned Terraform modules. This will allow you to make changes without affecting other environments. Here's an example of what that would look like.

*staging/main.tf*
```
module "sippin_db" {
  source           = "github.com/cmndrsp0ck/galera-tf-mod.git?ref=v1.0.4"
  project          = "${var.project}"
  region           = "${var.region}"
  keys             = "${var.keys}"
  private_key_path = "${var.private_key_path}"
  ssh_fingerprint  = "${var.ssh_fingerprint}"
  public_key       = "${var.public_key}"
  ansible_user     = "${var.ansible_user}"
}
```

*prod/main.tf*
```
module "sippin_db" {
  source           = "github.com/cmndrsp0ck/galera-tf-mod.git?ref=v1.0.2"
  project          = "${var.project}"
  region           = "${var.region}"
  keys             = "${var.keys}"
  private_key_path = "${var.private_key_path}"
  ssh_fingerprint  = "${var.ssh_fingerprint}"
  public_key       = "${var.public_key}"
  ansible_user     = "${var.ansible_user}"
}
```

The only change in the previous 2 examples is the value assigned to the *ref* key at the end of the source line. Maybe you wanted to switch from spinning up your own load balancers to a DigitalOcean Load Balancer, or you're adding some additional nodes to the Galera cluster as async slaves. Using version control will allow you to make, and test that change in staging before deploying to production.

I recommend checking out Terraform's documentation on how to create a module. It's very simple and as shown, very helpful. Check out https://www.terraform.io/docs/modules/index.html. Now that we've simplified our code by making it modular and shown how to isolate environments for safer development and deployments, let's look at how we can increase our deploy velocity by creating templates.
