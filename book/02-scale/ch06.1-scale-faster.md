**Using snapshots to scale faster**

So far we've spun up a DigitalOcean Load Balancer with a few application backends running WordPress, and a load balanced Galera cluster. During the deployment of WordPress you should have noticed that one of the tasks seems to take a while due to running through a listing of directories to change the setgid bit. Spinning up base images and installing all dependencies and making configuration changes when you need to increase your application's capacity is not efficient. To speed things up and minimize the amount of work required to add new backends you can simply create your own images with all of your software dependencies pre-baked.

Creating a template can be manual process if you'd like. That means spinning up a single Droplet, logging in and running through all of the steps one-by-one, testing it out, then finally creating a snapshot. This isn't very practical though since it can be a slow, error prone process. A step in the right direction would be to script the process. You can use whatever language you're comfortable with. Often times using bash scripts works well for simple builds but keep in mind that as your project requirements grow, your scripts will too, along with the effort required to maintain those scripts.

Another option would be to use server templating tool like Packer. Now while Packer isn't going to configure your image for you on its own, it does allow you to easily create a repeatable and testable process. Packer works with the scripts you already have and supports a large set of additional configuration tools including Chef, Puppet, Salt, and Ansible. It also has the ability to work with tons of providers and is able to generate multiple image formats including Docker. We're going to make use of Packer's Ansible remote provisioner to create an image with WordPress and all of its dependencies installed.

Packer templates are written using JSON to describe the builds it will perform. It's a straightforward approach that allows you to get your images created quickly. For an in-depth view of the components that can be used in a template file check out https://www.packer.io/docs/templates/index.html. Here's the example template that we'll be using.

**ghost-node.json**
```json
{
    "builders": [
        {
            "type": "digitalocean",
            "api_token": "{{user `do_api_token`}}",
            "image": "{{user `app_node_image`}}",
            "region": "sfo2",
            "size": "s-1vcpu-1gb",
            "private_networking": true,
            "monitoring": true,
            "user_data_file": "./config/cloud-config.yaml",
            "snapshot_name": "{{user `project_name`}}_{{isotime \"06-01-02-03-04-05\"}}",
            "communicator": "ssh",
            "ssh_username": "root"
        }
    ],
    "provisioners": [
        {
            "type": "ansible",
            "playbook_file": "wordpress.yml",
            "ansible_env_vars": [ "ANSIBLE_HOST_KEY_CHECKING=False", "ANSIBLE_SSH_ARGS='-o ForwardAgent=yes -o ControlMaster=auto -o ControlPersist=60s'"],
            "extra_arguments": ["-vvv"],
            "inventory_directory": "{{template_dir}}",
            "user": "root"
        }
    ],
    "post-processors": [
        {
            "type": "manifest",
            "output": "manifest.json",
            "strip_path": true
        }
    ]
}
```

So the first part we're describing is the builder. This is responsible for declaring what type of image will be produced, and in our case that means the cloud provider we'll be setting the image up with. Each builder takes a number of arguments to set what base image to use, the Droplet size, region availability, pass in user-data, set the snapshot name and any connection settings. Also note that Packer allows you to set variables and has some built-in functions that cab be used throughout the template file. Anything that is placed within `{{ }}` is run through the packer template engine. For a full listing of functions check out https://www.packer.io/docs/templates/engine.html. You'll notice that some of the values are variables, but the variables are not listed in this file. You're able to create a separate file in order to store variables and pass the file to Packer as a command-line argument when executing your template by using `-var-file=`. This allows you to set the file name in your **.gitignore** so it doesn't get sent up to your repo. You don't really have to place base image type, or the project name in this file along with the API token, but for the sake of organization we'll keep all the variables in one file. Here's an example variable file.

**variable.json**
```json
{
	"app_node_image": "debian-9-x64",
	"do_api_token": "1r7l8dsmd6g09g56qdwakvkjzvn4q046wwfolqeputcgz5og26vyheg781f5bvbz",
	"project_name": "nav-guide"
}
```

We're passing in a cloud-config.yaml file just to make sure that we install any dependencies for our provisioner which is going to be Ansible. We're using Ansible to keep things organized, clean, and should then need arise, you can run some playbooks later on your existing infrastructure and know that steps won't be ran again since it's idempotent. Packer is going to take care of create the Droplet and supplying the private key and inventory to Ansible. All you need to do is toss in any flags you think are necessary and you're good to go.

The last section covering the *post-processors* is not required, but we're going to use it later on. This is simply going to output a listing of completed builds that Packer has created and store them in a file. We'll extract the snapshot ID from the file once we're ready to use it.
